# -*- coding: utf-8 -*-
"""
vision_server.py: [ìµœì¢…ë³¸] C í”„ë¡œì„¸ìŠ¤ì˜ ìš”ì²­ì„ ë°›ì•„ GStreamerë¡œë¶€í„° 1í”„ë ˆì„ì„ ê°€ì ¸ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.
- ì—­í• : Cì˜ ìš”ì²­ì— ë”°ë¼ AI ë¶„ì„ ì„œë¹„ìŠ¤ë§Œ ì œê³µí•˜ëŠ” 'ì „ë¬¸ê°€'.
- ë™ì‘: í‰ì†Œì—ëŠ” Cì˜ ëª…ë ¹ì„ ê¸°ë‹¤ë¦¬ë©° ëŒ€ê¸°(ä¼‘). ëª…ë ¹ì„ ë°›ìœ¼ë©´ ì¦‰ì‹œ ì„ë¬´(ë¶„ì„)ë¥¼ ìˆ˜í–‰í•˜ê³  ë³´ê³ (ê²°ê³¼ ì „ì†¡).
"""

import sys
import json
import gi
import numpy as np
# LDH gií´ë˜ìŠ¤ êµ¬í˜„ì„ ìœ„í•œ import ì‹œì‘
import gi, numpy as np, time, cv2
import threading
from gi.repository import Gst, GstApp, GstVideo
# LDH gií´ë˜ìŠ¤ êµ¬í˜„ì„ ìœ„í•œ import ë
import bev


# ===== ì…ë ¥(ì¹´ë©”ë¼) =====
SRC_W, SRC_H = 800, 320
ROWS, COLS   = 2, 3
NUM_CAMERAS  = ROWS * COLS  # 6

# ===== ì¶œë ¥(íƒ€ì¼) =====
TILE_W, TILE_H = 266, 240
OUT_W, OUT_H   = 800 , 480
OUT_FPS        = 15


SINK_PIPELINE = "videoconvert ! kmssink sync=false"
SINK_CAPS = f"video/x-raw,format=RGBx,width={OUT_W},height={OUT_H},framerate={OUT_FPS}/1"


# GStreamer ë° GObject ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ.
gi.require_version('Gst', '1.0')
gi.require_version('GstApp', '1.0')     # ì¶”ê°€ 
gi.require_version('GstVideo', '1.0')   # ì¶”ê°€

# LDH GstVideoReceiver class ì„ ì–¸ ì‹œì‘
class GstVideoReceiver:
    def __init__(self, port):
        self.port           = port
        self.pipeline       = None
        self.appsink        = None
        self.bus            = None
        self.is_initialized = False
        self.latest_frame   = None
        self._stop          = False
        self._thread        = None

    def init_pipeline(self):
        pipeline_str = (
            f"udpsrc port={self.port} ! "
            "application/x-rtp,media=video,encoding-name=H264,payload=96 ! "
            "rtpjitterbuffer latency=60 ! "
            "rtph264depay ! h264parse config-interval=-1 ! "
            "avdec_h264 max-threads=1 ! "
            "videoconvert ! "
            "video/x-raw,format=RGB ! "   # appsinkì— RGBë¡œ ì „ë‹¬
            "appsink name=sink drop=true max-buffers=1 sync=false"
        )
        self.pipeline = Gst.parse_launch(pipeline_str)
        self.bus      = self.pipeline.get_bus()
        self.appsink  = self.pipeline.get_by_name("sink")

        ret = self.pipeline.set_state(Gst.State.PLAYING)
        if ret == Gst.StateChangeReturn.FAILURE:
            self.pipeline.set_state(Gst.State.NULL)
            raise RuntimeError(f"RX pipeline start failed on port {self.port}")
        self.is_initialized = True
        self._drain_bus()
        return True

    def _drain_bus(self):
        while True:
            msg = self.bus.pop()
            if not msg:
                break
            if msg.type == Gst.MessageType.ERROR:
                err, dbg = msg.parse_error()
                print(f"[RX:{self.port}][ERROR] {err.message}  debug={dbg}")
            elif msg.type == Gst.MessageType.WARNING:
                w, dbg = msg.parse_warning()
                print(f"[RX:{self.port}][WARN] {w.message}  debug={dbg}")

    def _pull_frame(self):
        sample = self.appsink.try_pull_sample(50 * Gst.MSECOND)
        if not sample:
            self._drain_bus()
            return None

        buf  = sample.get_buffer()
        caps = sample.get_caps()
        s    = caps.get_structure(0)
        w, h = int(s.get_value("width")), int(s.get_value("height"))
        fmt  = s.get_value("format")
        #print(f"[RX:{self.port}] got frame {w}x{h} fmt={fmt}")  # ë””ë²„ê·¸ ë¡œê·¸

        ok, mapinfo = buf.map(Gst.MapFlags.READ)
        if not ok:
            return None

        try:
            data = np.frombuffer(mapinfo.data, dtype=np.uint8)
            frame = data.reshape((h, w, 3))   # RGB 3ì±„ë„
            return frame
        finally:
            buf.unmap(mapinfo)

    def _loop(self):
        while not self._stop:
            frame = self._pull_frame()
            if frame is not None:
                self.latest_frame = frame

    def start(self):
        self._stop = False
        self._thread = threading.Thread(target=self._loop, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop = True
        if self._thread:
            self._thread.join()
            self._thread = None

        if self.is_initialized and self.pipeline:
            # ìƒíƒœ NULLë¡œ ì „í™˜
            self.pipeline.set_state(Gst.State.NULL)
            # ì „í™˜ ì™„ë£Œ ëŒ€ê¸° (ì¤‘ìš”)
            self.pipeline.get_state(Gst.CLOCK_TIME_NONE)
            # ë ˆí¼ëŸ°ìŠ¤ ì •ë¦¬
            self.appsink = None
            self.bus = None
            self.pipeline = None
            self.is_initialized = False

# LDH GstVideoReceiver class ì„ ì–¸ ë
# LDH DisplayRGB class ì„ ì–¸ ì‹œì‘

class DisplayRGB:
    def __init__(self):
        desc = (
            "appsrc name=src is-live=true do-timestamp=true format=time "
            f"caps={SINK_CAPS} ! queue ! {SINK_PIPELINE}"
        )
        self.pipeline = Gst.parse_launch(desc)
        self.bus      = self.pipeline.get_bus()
        self.appsrc   = self.pipeline.get_by_name("src")

        ret = self.pipeline.set_state(Gst.State.PLAYING)
        if ret == Gst.StateChangeReturn.FAILURE:
            self.pipeline.set_state(Gst.State.NULL)
            raise RuntimeError("Display pipeline start failed (RGB)")
        self._drain_bus()

    def _drain_bus(self):
        while True:
            msg = self.bus.pop()
            if not msg:
                break
            if msg.type == Gst.MessageType.ERROR:
                err, dbg = msg.parse_error()
                print(f"[Display][ERROR] {err.message}  debug={dbg}")
            elif msg.type == Gst.MessageType.WARNING:
                w, dbg = msg.parse_warning()
                print(f"[Display][WARN] {w.message}  debug={dbg}")

    def push_rgb(self, frame_bgr):
        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        frame_rgbx = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2RGBA)   # RGBA = RGBx
        frame_rgbx = np.ascontiguousarray(frame_rgbx, dtype=np.uint8)

        buf = Gst.Buffer.new_wrapped(frame_rgbx.tobytes())
        ts = int(time.time() * Gst.SECOND)
        buf.pts = ts
        buf.dts = ts
        buf.duration = Gst.SECOND // OUT_FPS

        self.appsrc.emit("push-buffer", buf)

    def close(self):
        if not self.pipeline:
            return
        try:
            # ë¨¼ì € EOSë¡œ íŒŒì´í”„ë¼ì¸ì— ì¢…ë£Œë¥¼ ì•Œë¦¼ (ê¶Œì¥)
            try:
                self.appsrc.end_of_stream()
            except Exception:
                pass
            # NULL ì „ì´
            self.pipeline.set_state(Gst.State.NULL)
            self.pipeline.get_state(Gst.CLOCK_TIME_NONE)
        finally:
            self.appsrc = None
            self.bus = None
            self.pipeline = None
# LDH DisplayRGB class ì„ ì–¸ ë

# LDH imsië¡œ ë„ì›Œì¤„ê±° ì‹œê°„ì´ì´ëœë‹¤ë©´ Mapí• ë•Œ ìˆ˜ì •ë  ê²ƒ 
def tile_grid_rgb(frames, rows=ROWS, cols=COLS, tile_w=TILE_W, tile_h=TILE_H):
    total = rows * cols
    padded = list(frames)[:total]
    while len(padded) < total:
        padded.append(np.zeros((SRC_H, SRC_W, 3), dtype=np.uint8))  # RGB ê²€ì •
    tiles = []
    idx = 0
    for _ in range(rows):
        row_imgs = []
        for _ in range(cols):
            f = padded[idx]
            if f is None:
                f = np.zeros((SRC_H, SRC_W, 3), dtype=np.uint8)
            row_imgs.append(cv2.resize(f, (tile_w, tile_h)))
            idx += 1
        tiles.append(np.hstack(row_imgs))
    return np.vstack(tiles)  # RGB

# ---------------------------LDH model input ì„ ìœ„í•œ ë³µì‚¬ ë° ë³€í™˜ ì‹œì‘
def resize_with_letterbox(img, target_w=800, target_h=320):
    h, w = img.shape[:2]
    scale = min(target_w / w, target_h / h)
    new_w, new_h = int(w * scale), int(h * scale)

    resized = cv2.resize(img, (new_w, new_h))
    canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)
    top = (target_h - new_h) // 2
    left = (target_w - new_w) // 2
    canvas[top:top+new_h, left:left+new_w] = resized
    return canvas

def normalize_imagenet(img):
    img = img.astype(np.float32) / 255.0
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    img = (img - mean) / std
    return img

def copy_for_model(displayFrames, target_w=800, target_h=320):
    processed = []
    for img in displayFrames:
        if img is None:
            img = np.zeros((target_h, target_w, 3), dtype=np.uint8)  # ë¹ˆ í™”ë©´ ëŒ€ì²´
        img_proc = resize_with_letterbox(img, target_w, target_h)
        img_proc = normalize_imagenet(img_proc)
        img_proc = np.transpose(img_proc, (2, 0, 1))
        processed.append(img_proc)

    modelFrames = np.stack(processed, axis=0)
    modelFrames = np.expand_dims(modelFrames, axis=0)
    return modelFrames
# ---------------------------LDH model input ì„ ìœ„í•œ ë³µì‚¬ ë° ë³€í™˜ ë


def log(message):
    """ë””ë²„ê¹… ë©”ì‹œì§€ë¥¼ í‘œì¤€ ì—ëŸ¬(stderr)ë¡œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜. Cë¡œ ê°€ëŠ” ë°ì´í„°(stdout)ì™€ ì„ì´ì§€ ì•Šê²Œ í•¨."""
    print(f"[Py LOG] {message}", file=sys.stderr, flush=True)

def get_single_frame(appsink):
    """
    appsinkë¡œë¶€í„° í”„ë ˆì„(ìƒ˜í”Œ)ì„ ë‹¨ í•˜ë‚˜ë§Œ ê°€ì ¸ì™€ NumPy ë°°ì—´ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    """
    # "pull-sample" ì‹œê·¸ë„ì€ appsinkì˜ ë‚´ë¶€ ë²„í¼ì—ì„œ ìƒ˜í”Œì„ êº¼ë‚´ì˜¤ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    sample = appsink.emit("pull-sample")
    if not sample:
        log("Failed to pull sample from appsink. Is the stream running?")
        return None

    # ìƒ˜í”Œì—ì„œ ë²„í¼(ì‹¤ì œ ë°ì´í„°)ì™€ ìº¡ìŠ(ë°ì´í„° í˜•ì‹ ì •ë³´)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    buf = sample.get_buffer()
    caps = sample.get_caps()
    structure = caps.get_structure(0)
    height = structure.get_value("height")
    width = structure.get_value("width")
    
    # GStreamer ë²„í¼ ë©”ëª¨ë¦¬ë¥¼ Pythonì´ ì½ì„ ìˆ˜ ìˆë„ë¡ ë§¤í•‘í•©ë‹ˆë‹¤.
    result, mapinfo = buf.map(Gst.MapFlags.READ)
    if result:
        # ë§¤í•‘ëœ ë©”ëª¨ë¦¬ ë°ì´í„°ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        numpy_frame = np.frombuffer(mapinfo.data, dtype=np.uint8).reshape(height, width, -1)
        buf.unmap(mapinfo) # ë©”ëª¨ë¦¬ ë§¤í•‘ í•´ì œ
        return numpy_frame
    return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    log("On-demand analysis script started.")
    
    # --- 1. GStreamer íŒŒì´í”„ë¼ì¸ ì„¤ì • ---
    Gst.init(None)
    # [appsink ì„¤ì •ì´ í•µì‹¬]
    # - max-buffers=1: í”„ë ˆì„ì„ ìµœëŒ€ 1ê°œë§Œ ì €ì¥. (ë©”ëª¨ë¦¬ ì ˆì•½)
    # - drop=true: ë²„í¼ê°€ ê½‰ ì°¼ì„ ë•Œ ìƒˆ í”„ë ˆì„ì´ ì˜¤ë©´, 'í—Œ í”„ë ˆì„ì€ ë²„ë¦¬ê³ ' ìƒˆ ê²ƒìœ¼ë¡œ êµì²´.
    # -> ì´ ë‘ ì„¤ì • ë•ë¶„ì— Cì˜ ìš”ì²­ì´ ëœ¸í•´ë„ ë°ì´í„°ê°€ ìŒ“ì´ì§€ ì•Šê³ , í•­ìƒ 'ê°€ì¥ ìµœì‹  í”„ë ˆì„'ë§Œ ìœ ì§€ë©ë‹ˆë‹¤.
    # pipeline_str = (
    #     "udpsrc port=5000 ! "
    #     "application/x-rtp, media=video, clock-rate=90000, encoding-name=H264, payload=96 ! "
    #     "rtph264depay ! h264parse ! avdec_h264 ! videoconvert ! "
    #     "video/x-raw,format=BGR ! appsink name=sink max-buffers=1 drop=true"
    # )
    # pipeline = Gst.parse_launch(pipeline_str)
    # appsink = pipeline.get_by_name('sink')
    # pipeline.set_state(Gst.State.PLAYING)

    # LDH pipelineì„ í†µí•´ ì´ë¯¸ì§€ ë°›ëŠ” ê°ì²´ ìƒì„± ì‹œì‘ 
    receivers = [GstVideoReceiver(5000 + i) for i in range(NUM_CAMERAS)]
    for r in receivers:
        r.init_pipeline()
        r.start()

    display = DisplayRGB()
    # LDH pipelineì„ í†µí•´ ì´ë¯¸ì§€ ë°›ëŠ” ê°ì²´ ìƒì„± ë

    log("GStreamer pipeline is running. Waiting for commands from C via stdin.")

    try:
        period = 1.0 / OUT_FPS
        next_t = time.time()
        # --- 2. Cë¡œë¶€í„°ì˜ ëª…ë ¹ì„ ê¸°ë‹¤ë¦¬ëŠ” ë©”ì¸ ë£¨í”„ ---
        while True:
            # sys.stdin.readline()ì€ Cì—ì„œ ëª…ë ¹ì„ ë³´ë‚¼ ë•Œê¹Œì§€ ì—¬ê¸°ì„œ ì‹¤í–‰ì„ ë©ˆì¶”ê³  ëŒ€ê¸°í•©ë‹ˆë‹¤.
            # ì´ê²ƒì´ ì´ ìŠ¤í¬ë¦½íŠ¸ì˜ ê¸°ë³¸ 'ëŒ€ê¸° ìƒíƒœ'ì…ë‹ˆë‹¤.
            #command = sys.stdin.readline()
            command = "analyze"
            if not command:
                log("C process closed the pipe. Exiting.")
                break
            
            log(f"Received command from C: {command.strip()}")
            
            if "analyze" in command.strip():
                #frame = get_single_frame(appsink)
                displayFrames = [] #ì´ë¯¸ì§€ ë„£ì„ ë¦¬ìŠ¤íŠ¸
                modelFrames = []
                displayFrames = [r.latest_frame for r in receivers]   # ê° í”„ë ˆì„: RGB ë˜ëŠ” None
                
                for i in range(len(displayFrames)):
                    if displayFrames[i] is None:
                        displayFrames[i] = np.zeros((SRC_H, SRC_W, 3), dtype=np.uint8)
                    else:
                        displayFrames[i] = cv2.cvtColor(displayFrames[i], cv2.COLOR_BGR2RGB)
                displayFrames = np.array(displayFrames)  # numpy í˜•íƒœì—¬ì•¼ shapeë„ ê°€ëŠ¥í•¨
                #frames = np.transpose(frames, (0, 3, 1, 2)) 
                modelFrames = copy_for_model(displayFrames)# 1,6,3,320,800ë¡œ ë³€í™˜ ë ê²ƒì„

                grid   = tile_grid_rgb(displayFrames, ROWS, COLS, TILE_W, TILE_H)  # RGB

                grid = cv2.resize(grid, (OUT_W, OUT_H), interpolation=cv2.INTER_LINEAR)

                display.push_rgb(grid)  # RGB ê·¸ëŒ€ë¡œ ì¶œë ¥ imsi UIë‚˜ì¤‘ì— ë§Œë“¤ì–´ì§€ë©´ ê·¸ë•Œ ë‹¤ì‹œ

                if modelFrames is not None:
                    # [ ì—¬ê¸°ì— ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ì½”ë“œë¥¼ ì‚½ì…í•©ë‹ˆë‹¤. ]


                    # ==============================
                    # ğŸš€ ì—¬ê¸°ì— BEV ì¶”ë¡  ì‚½ì…
                    # ==============================
                    try:
                        # backbone ì‹¤í–‰
                        bb_out, bb_meta = core.backbone_infer(target, modelFrames, backbone_hef_path)

                        # transformer ì‹¤í–‰
                        tf_out, tf_meta = core.transformer_infer(target, bb_out, bb_meta,
                                                                 transformer_hef_path, matmul_path)

                        # í›„ì²˜ë¦¬ (onnx)
                        post_out = pre_post_process.post_proc_infer(tf_out, tf_meta, post_proc_onnx_path)

                        # NMS
                        final_results = pre_post_process.d3nms_infer(post_out, nusc)

                        ai_result = {"status": "success", "detections": final_results}
                        log(f"Frame analysis complete. Got {len(final_results)} objects.")
                    except Exception as e:
                        ai_result = {"status": "fail", "reason": str(e)}
                        log(f"Frame analysis failed: {e}")
                    # ==============================
                    ai_result = {"status": "success", "frame_shape": modelFrames.shape}
                    log(f"Frame analysis complete. Shape: {modelFrames.shape}")
                else:
                    ai_result = {"status": "fail", "reason": "Could not get frame from GStreamer"}
                    log("Frame analysis failed.")
                
                # ë¶„ì„ ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ í‘œì¤€ ì¶œë ¥(stdout)ìœ¼ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
                # ì´ stdoutì€ Cì˜ íŒŒì´í”„ì™€ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
                print(json.dumps(ai_result))
                # [ì¤‘ìš”] ë²„í¼ë¥¼ ë¹„ì›Œ ë°ì´í„°ê°€ ì¦‰ì‹œ Cë¡œ ì „ì†¡ë˜ê²Œ í•©ë‹ˆë‹¤.
                sys.stdout.flush()

    except KeyboardInterrupt:
        log("KeyboardInterrupt caught, exiting.")
    finally:
        # ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ ì‹œ íŒŒì´í”„ë¼ì¸ì„ ì •ì§€ì‹œì¼œ ìì›ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
        # pipeline.set_state(Gst.State.NULL)
        for r in receivers:
            r.stop()
        
        if display:
            display.close()    
        cv2.destroyAllWindows()
        log("Pipeline stopped. Script finished.")

if __name__ == '__main__':
    main()